{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入pytorch库\n",
    "import torch\n",
    "# 导入torch.nn模块\n",
    "from torch import nn\n",
    " \n",
    " \n",
    "# 定义LeNet网络模型\n",
    "# MyLeNet5（子类）继承nn.Module（父类）\n",
    "class MyLeNet5(nn.Module):\n",
    "    # 子类继承中重新定义Module类的__init__()和forward()函数\n",
    "    # init()函数：进行初始化，申明模型中各层的定义\n",
    "    def __init__(self):\n",
    "        # super：引入父类的初始化方法给子类进行初始化\n",
    "        super(MyLeNet5, self).__init__()\n",
    "        # 卷积层，输入大小为28*28，输出大小为28*28，输入通道为1，输出为6，卷积核为5，扩充边缘为2\n",
    "        self.c1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, padding=2)\n",
    "        # 使用sigmoid作为激活函数\n",
    "        self.Sigmoid = nn.Sigmoid()\n",
    "        # AvgPool2d：二维平均池化操作\n",
    "        # 池化层，输入大小为28*28，输出大小为14*14，输入通道为6，输出为6，卷积核为2，步长为2\n",
    "        self.s2 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "        # 卷积层，输入大小为14*14，输出大小为10*10，输入通道为6，输出为16，卷积核为5\n",
    "        self.c3 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)\n",
    "        # 池化层，输入大小为10*10，输出大小为5*5，输入通道为16，输出为16，卷积核为2，步长为2\n",
    "        self.s4 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "        # 卷积层，输入大小为5*5，输出大小为1*1，输入通道为16，输出为120，卷积核为5\n",
    "        self.c5 = nn.Conv2d(in_channels=16, out_channels=120, kernel_size=5)\n",
    "        # Flatten()：将张量（多维数组）平坦化处理，张量的第0维表示的是batch_size（数量），所以Flatten()默认从第二维开始平坦化\n",
    "        self.flatten = nn.Flatten()\n",
    "        # 全连接层\n",
    "        # Linear（in_features，out_features）\n",
    "        # in_features指的是[batch_size, size]中的size,即样本的大小\n",
    "        # out_features指的是[batch_size，output_size]中的output_size，样本输出的维度大小，也代表了该全连接层的神经元个数\n",
    "        self.f6 = nn.Linear(120, 84)\n",
    "        # 全连接层&输出层\n",
    "        self.output = nn.Linear(84, 10)\n",
    " \n",
    "    # forward()：定义前向传播过程,描述了各层之间的连接关系\n",
    "    def forward(self, x):\n",
    "        # x输入为28*28*1， 输出为28*28*6\n",
    "        x = self.Sigmoid(self.c1(x))\n",
    "        # x输入为28*28*6，输出为14*14*6\n",
    "        x = self.s2(x)\n",
    "        # x输入为14*14*6，输出为10*10*16\n",
    "        x = self.Sigmoid(self.c3(x))\n",
    "        # x输入为10*10*16，输出为5*5*16\n",
    "        x = self.s4(x)\n",
    "        # x输入为5*5*16，输出为1*1*120\n",
    "        x = self.c5(x)\n",
    "        x = self.flatten(x)\n",
    "        # x输入为120，输出为84\n",
    "        x = self.f6(x)\n",
    "        # x输入为84，输出为10\n",
    "        x = self.output(x)\n",
    "        return x\n",
    " \n",
    "# 测试代码\n",
    "# 每个python模块（python文件）都包含内置的变量 __name__，当该模块被直接执行的时候，__name__ 等于文件名（包含后缀 .py ）\n",
    "# 如果该模块 import 到其他模块中，则该模块的 __name__ 等于模块名称（不包含后缀.py）\n",
    "# “__main__” 始终指当前执行模块的名称（包含后缀.py）\n",
    "# if确保只有单独运行该模块时，此表达式才成立，才可以进入此判断语法，执行其中的测试代码，反之不行\n",
    "if __name__ == \"__main__\":\n",
    "    # rand:返回一个张量，包含了从区间[0, 1)的均匀分布中抽取的一组随机数，此处为四维张量\n",
    "    x = torch.rand([1, 1, 28, 28])\n",
    "    # 模型实例化\n",
    "    model = MyLeNet5()\n",
    "    y = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0492,  0.0828,  0.1224,  0.1630, -0.1698, -0.0234,  0.0862, -0.2070,\n",
       "          0.1009, -0.0197]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [02:07<00:00, 77824.98it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 50978.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [01:18<00:00, 20872.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "epoch 1\n",
      "---------------\n",
      "train_loss2.3018843083699543\n",
      "train_acc0.11191666666666666\n",
      "val_loss：2.299332925415039\n",
      "val_acc：0.1009\n",
      "save best model\n",
      "epoch 2\n",
      "---------------\n",
      "train_loss2.2905562575658163\n",
      "train_acc0.13905\n",
      "val_loss：2.2497605739593505\n",
      "val_acc：0.2089\n",
      "save best model\n",
      "epoch 3\n",
      "---------------\n",
      "train_loss1.3241605015476545\n",
      "train_acc0.56615\n",
      "val_loss：0.5380169923186302\n",
      "val_acc：0.8336\n",
      "save best model\n",
      "epoch 4\n",
      "---------------\n",
      "train_loss0.4690105177929004\n",
      "train_acc0.8565666666666667\n",
      "val_loss：0.3932179854631424\n",
      "val_acc：0.8821\n",
      "save best model\n",
      "epoch 5\n",
      "---------------\n",
      "train_loss0.37219019476075965\n",
      "train_acc0.8878166666666667\n",
      "val_loss：0.3215369183778763\n",
      "val_acc：0.9071\n",
      "save best model\n",
      "epoch 6\n",
      "---------------\n",
      "train_loss0.3244854424521327\n",
      "train_acc0.9016833333333333\n",
      "val_loss：0.2978317408025265\n",
      "val_acc：0.9118\n",
      "save best model\n",
      "epoch 7\n",
      "---------------\n",
      "train_loss0.28876867005278667\n",
      "train_acc0.9132833333333333\n",
      "val_loss：0.26066217656731605\n",
      "val_acc：0.9218\n",
      "save best model\n",
      "epoch 8\n",
      "---------------\n",
      "train_loss0.25459097176479795\n",
      "train_acc0.9223333333333333\n",
      "val_loss：0.2216204686537385\n",
      "val_acc：0.9358\n",
      "save best model\n",
      "epoch 9\n",
      "---------------\n",
      "train_loss0.22045870480475327\n",
      "train_acc0.9333\n",
      "val_loss：0.1935546375475824\n",
      "val_acc：0.9403\n",
      "save best model\n",
      "epoch 10\n",
      "---------------\n",
      "train_loss0.18921848092104\n",
      "train_acc0.9432166666666667\n",
      "val_loss：0.15739058701097966\n",
      "val_acc：0.9524\n",
      "save best model\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# lr_scheduler：提供一些根据epoch训练次数来调整学习率的方法\n",
    "from torch.optim import lr_scheduler\n",
    "# torchvision：PyTorch的一个图形库，服务于PyTorch深度学习框架的，主要用来构建计算机视觉模型\n",
    "# transforms：主要是用于常见的一些图形变换\n",
    "# datasets：包含加载数据的函数及常用的数据集接口\n",
    "from torchvision import datasets, transforms\n",
    "# os：operating system（操作系统），os模块封装了常见的文件和目录操作\n",
    "import os\n",
    "\n",
    "# 数据转化为Tensor格式\n",
    "# Compose()：将多个transforms的操作整合在一起\n",
    "# ToTensor(): 将numpy的ndarray或PIL.Image读的图片转换成形状为(C,H, W)的Tensor格式，且归一化到[0,1.0]之间\n",
    "data_transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    " \n",
    "# 加载训练数据集\n",
    "# MNIST数据集来自美国国家标准与技术研究所, 训练集 (training set)、测试集(test set)由分别由来自250个不同人手写的数字构成\n",
    "# MNIST数据集包含：Training set images、Training set images、Test set images、Test set labels\n",
    "# train = true是训练集，false为测试集\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, transform=data_transform, download=True)\n",
    "# DataLoader：将读取的数据按照batch size大小封装并行训练\n",
    "# dataset (Dataset)：加载的数据集\n",
    "# batch_size (int, optional)：每个batch加载多少个样本(默认: 1)\n",
    "# shuffle (bool, optional)：设置为True时会在每个epoch重新打乱数据(默认: False)\n",
    "train_dataloader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=16, shuffle=True)\n",
    "# 加载测试数据集\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, transform=data_transform, download=True)\n",
    "test_dataloader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=16, shuffle=True)\n",
    " \n",
    "# 如果有NVIDA显卡，转到GPU训练，否则用CPU\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    " \n",
    "# 模型实例化，将模型转到device\n",
    "model = MyLeNet5().to(device)\n",
    " \n",
    "# 定义损失函数（交叉熵损失）\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# 定义优化器(随机梯度下降法)\n",
    "# params(iterable)：要训练的参数，一般传入的是model.parameters()\n",
    "# lr(float)：learning_rate学习率，也就是步长\n",
    "# momentum(float, 可选)：动量因子（默认：0），矫正优化率\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3, momentum=0.9)\n",
    " \n",
    "# 学习率，每隔10轮变为原来的0.1\n",
    "# StepLR：用于调整学习率，一般情况下会设置随着epoch的增大而逐渐减小学习率从而达到更好的训练效果\n",
    "# optimizer （Optimizer）：需要更改学习率的优化器\n",
    "# step_size（int）：每训练step_size个epoch，更新一次参数\n",
    "# gamma（float）：更新lr的乘法因子\n",
    "lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    " \n",
    " \n",
    "# 定义训练函数\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    loss, current, n = 0.0, 0.0, 0\n",
    "    # dataloader: 传入数据（数据包括：训练数据和标签）\n",
    "    # enumerate()：用于将一个可遍历的数据对象(如列表、元组或字符串)组合为一个索引序列，一般用在for循环当中\n",
    "    # enumerate返回值有两个：一个是序号，一个是数据（包含训练数据和标签）\n",
    "    # x：训练数据（inputs）(tensor类型的），y：标签（labels）(tensor类型的）\n",
    "    for batch, (x, y) in enumerate(dataloader):\n",
    "        # 前向传播\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        # 计算训练值\n",
    "        output = model(x)\n",
    "        # 计算观测值（label）与训练值的损失函数\n",
    "        cur_loss = loss_fn(output, y)\n",
    "        # torch.max(input, dim)函数\n",
    "        # input是具体的tensor，dim是max函数索引的维度，0是每列的最大值，1是每行的最大值输出\n",
    "        # 函数会返回两个tensor，第一个tensor是每行的最大值；第二个tensor是每行最大值的索引\n",
    "        _, pred = torch.max(output, axis=1)\n",
    "        # 计算每批次的准确率\n",
    "        # output.shape[0]一维长度为该批次的数量\n",
    "        # torch.sum()对输入的tensor数据的某一维度求和\n",
    "        cur_acc = torch.sum(y == pred) / output.shape[0]\n",
    " \n",
    "        # 反向传播\n",
    "        # 清空过往梯度\n",
    "        optimizer.zero_grad()\n",
    "        # 反向传播，计算当前梯度\n",
    "        cur_loss.backward()\n",
    "        # 根据梯度更新网络参数\n",
    "        optimizer.step()\n",
    "        # .item()：得到元素张量的元素值\n",
    "        loss += cur_loss.item()\n",
    "        current += cur_acc.item()\n",
    "        n = n + 1\n",
    " \n",
    "    train_loss = loss / n\n",
    "    train_acc = current / n\n",
    "    # 计算训练的错误率\n",
    "    print('train_loss' + str(train_loss))\n",
    "    # 计算训练的准确率\n",
    "    print('train_acc' + str(train_acc))\n",
    " \n",
    " \n",
    "# 定义验证函数\n",
    "def val(dataloader, model, loss_fn):\n",
    "    # model.eval()：设置为验证模式，如果模型中有Batch Normalization或Dropout，则不启用，以防改变权值\n",
    "    model.eval()\n",
    "    loss, current, n = 0.0, 0.0, 0\n",
    "    # with torch.no_grad()：将with语句包裹起来的部分停止梯度的更新，从而节省了GPU算力和显存，但是并不会影响dropout和BN层的行为\n",
    "    with torch.no_grad():\n",
    "        for batch, (x, y) in enumerate(dataloader):\n",
    "            # 前向传播\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            output = model(x)\n",
    "            cur_loss = loss_fn(output, y)\n",
    "            _, pred = torch.max(output, axis=1)\n",
    "            cur_acc = torch.sum(y == pred) / output.shape[0]\n",
    "            loss += cur_loss.item()\n",
    "            current += cur_acc.item()\n",
    "            n = n + 1\n",
    "        # 计算验证的错误率\n",
    "        print(\"val_loss：\" + str(loss / n))\n",
    "        # 计算验证的准确率\n",
    "        print(\"val_acc：\" + str(current / n))\n",
    "        # 返回模型准确率\n",
    "        return current / n\n",
    " \n",
    "\n",
    "# 开始训练\n",
    "# 训练次数\n",
    "epoch = 10\n",
    "# 用于判断最佳模型\n",
    "min_acc = 0\n",
    "for t in range(epoch):\n",
    "    print(f'epoch {t + 1}\\n---------------')\n",
    "    # 训练模型\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    # 验证模型\n",
    "    a = val(test_dataloader, model, loss_fn)\n",
    "    # 保存最好的模型权重\n",
    "    if a > min_acc:\n",
    "        folder = 'save_model'\n",
    "        # path.exists：判断括号里的文件是否存在，存在为True，括号内可以是文件路径\n",
    "        if not os.path.exists(folder):\n",
    "            # os.mkdir() ：用于以数字权限模式创建目录\n",
    "            os.mkdir('save_model')\n",
    "        min_acc = a\n",
    "        print('save best model')\n",
    "        # torch.save(state, dir)保存模型等相关参数，dir表示保存文件的路径+保存文件名\n",
    "        # model.state_dict()：返回的是一个OrderedDict，存储了网络结构的名字和对应的参数\n",
    "        torch.save(model.state_dict(), 'save_model/best_model.pth')\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\62736\\AppData\\Local\\Temp\\ipykernel_13244\\372736179.py:28: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"D:/pycharm/file/save_model/best_model.pth\"))\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'D:/pycharm/file/save_model/best_model.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 28\u001b[0m\n\u001b[0;32m     25\u001b[0m model \u001b[38;5;241m=\u001b[39m MyLeNet5()\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# 加载train.py里训练好的模型\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mD:/pycharm/file/save_model/best_model.pth\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# 结果类型\u001b[39;00m\n\u001b[0;32m     31\u001b[0m classes \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m9\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     42\u001b[0m ]\n",
      "File \u001b[1;32mc:\\Users\\62736\\.conda\\envs\\torch\\lib\\site-packages\\torch\\serialization.py:1065\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1062\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m   1063\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m-> 1065\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[0;32m   1066\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[0;32m   1067\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[0;32m   1068\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[0;32m   1069\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[0;32m   1070\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[1;32mc:\\Users\\62736\\.conda\\envs\\torch\\lib\\site-packages\\torch\\serialization.py:468\u001b[0m, in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    466\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[0;32m    467\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[1;32m--> 468\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    469\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    470\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[1;32mc:\\Users\\62736\\.conda\\envs\\torch\\lib\\site-packages\\torch\\serialization.py:449\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[1;32m--> 449\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'D:/pycharm/file/save_model/best_model.pth'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms import ToPILImage\n",
    " \n",
    "# Compose()：将多个transforms的操作整合在一起\n",
    "data_transform = transforms.Compose([\n",
    "    # ToTensor()：数据转化为Tensor格式\n",
    "    transforms.ToTensor()\n",
    "])\n",
    " \n",
    "# 加载训练数据集\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, transform=data_transform, download=True)\n",
    "# 给训练集创建一个数据加载器, shuffle=True用于打乱数据集，每次都会以不同的顺序返回\n",
    "train_dataloader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=16, shuffle=True)\n",
    " \n",
    "# 加载测试数据集\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, transform=data_transform, download=True)\n",
    "test_dataloader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=16, shuffle=True)\n",
    " \n",
    "# 如果有NVIDA显卡，转到GPU训练，否则用CPU\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    " \n",
    "# 模型实例化，将模型转到device\n",
    "model = MyLeNet5().to(device)\n",
    " \n",
    "# 加载train.py里训练好的模型\n",
    "model.load_state_dict(torch.load(\"D:/pycharm/file/save_model/best_model.pth\"))\n",
    " \n",
    "# 结果类型\n",
    "classes = [\n",
    "    \"0\",\n",
    "    \"1\",\n",
    "    \"2\",\n",
    "    \"3\",\n",
    "    \"4\",\n",
    "    \"5\",\n",
    "    \"6\",\n",
    "    \"7\",\n",
    "    \"8\",\n",
    "    \"9\",\n",
    "]\n",
    " \n",
    "# 把Tensor转化为图片，方便可视化\n",
    "show = ToPILImage()\n",
    " \n",
    "# 进入验证阶段\n",
    "for i in range(10):\n",
    "    x, y = test_dataset[i][0], test_dataset[i][1]\n",
    "    # show()：显示图片\n",
    "    show(x).show()\n",
    "    # unsqueeze(input, dim)，input(Tensor)：输入张量，dim (int)：插入维度的索引，最终将张量维度扩展为4维\n",
    "    x = Variable(torch.unsqueeze(x, dim=0).float(), requires_grad=False).to(device)\n",
    "    with torch.no_grad():\n",
    "        pred = model(x)\n",
    "        # argmax(input)：返回指定维度最大值的序号\n",
    "        # 得到验证类别中数值最高的那一类，再对应classes中的那一类\n",
    "        predicted, actual = classes[torch.argmax(pred[0])], classes[y]\n",
    "        # 输出预测值与真实值\n",
    "        print(f'predicted: \"{predicted}\", actual:\"{actual}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
